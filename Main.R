# Statement ----
# The analysis of this research includes 3 parts: general statistic analysis of tree attribute; interpolation of ecosystem services (ES), and analysis of the results. 
# For the first part, we calculated the common species of each land use, the tree attributes of each land use, etc. 
# For the second part, the ES-related investigation data of each quadrat was stored in Excel or *.csv tables. These data was joined to the sample quadrat GIS point layer, so that ArcGIS can access the data. Then multiple interpolation methods were applied using ArcGIS. In the interpolation, cross-validation results are generated by ArcGIS with leave-one-out method (see manuscript for details). The cross-validation results went back to R so that we can calculate MAE and RMSE and pick up the best interpolation method which has the lowest errors.
# For the third part, the analysis of the results includes calculating ES values of each land use, the relationship between ES spatial pattern and the other urban planning layers, e.g., parks, infrastructures, etc. 

# Package ----
pacman::p_load(
  openxlsx, units, dplyr, tidyr, ggplot2, shapefiles, sf, terra, tmap, vegan
)

# Setting ----
install_unit("yen")
install_unit("dollar", "109 yen")
install_unit("quadrat", "400 m2")

# Function ----
# Function: get total certain ESV of all land use types. 
# Note: extract ES interpolation results based on land use *.shp data, then calculate the sum of ES of the extracted data. 
# Argument: 
# x: a sf containing ESV data; 
# es: name of target ES. 
SumESVLanduse <- function(x, es) {
  result <- numeric(length = length(kLanduse))
  names(result) <- kLanduse
  for (i in kLanduse) {
    result[i] <- x %>% 
      mask(., subset(land.use, land_use == i)) %>% 
      global(fun = "sum", na.rm = TRUE) %>% 
      .[1, 1]
  }
  return(result)
}

# Function: read *.dbf file based on file name. 
# Note: Since the interpolation results are stored in the directories in this manner: InterpolationMethodName > EcosystemServiceName, I use the name of the interpolation method and the name of ES as the variable, though they should be the directory name and file name. This function reads the *.dbf table, then add columns of the directory (interpolation method) and file name (ES). 
# Argument: 
# intrpl: interpolation method name, which is actually directory of folder containing target *.dbf; 
# es: name of the target ES, which is actually the *.dbf file name. 
ReadDbf <- function(es, intrpl) {
  read.dbf(paste0("RawData/Validation/", intrpl, "/", es, ".dbf")) %>% 
    .$dbf %>% 
    as_tibble() %>%  
    rename_with(tolower) %>%
    select(measured, predicted) %>% 
    mutate(intrpl = intrpl, es = es, .before = measured)
}

# Data ----
## Constant ----
# Rate of Japanese Yen and US dollar: average rate of 2019. 
kUsdJpy <- set_units(109, yen/dollar)

# Ecosystem service items. 
kES <- data.frame(
  # ES names in this code
  es = c("carbon_stor", "carbon_seq", 
         "no2_rem", "o3_rem", "pm25_rem", "so2_rem", "ro_rd"), 
  # ES names of EBK interpolation result layers from ArcGIS. 
  abbr = c("CS", "CSE", 
             "NO2", "O3", "PM2.5", "SO2", "RR")
) %>% 
  mutate(esv = paste0(es, "_val"))

# Land use type. 
kLanduse <- 
  c("ResLow", "ResHigh", "ResOther", "Ind", "ComNbr", "Com")

## Quadrat information ----
qua.info <- 
  read.xlsx("RawData/Quadrat_info.xlsx", sheet = "QuaInfo") %>% 
  rename_with(tolower) %>% 
  rename(kes_qua_id = kes_plot_id, ward = ward_en) %>% 
  select(qua_id, kes_qua_id, landuse_class, ward) %>% 
  rename(landuse = landuse_class) %>% 
  tibble() %>% 
  # change names of land use column
  mutate(landuse = case_when(
    landuse == "Com" ~ "Com", 
    landuse == "Com-neigh" ~ "ComNbr", 
    landuse == "Ind" ~ "Ind", 
    landuse == "R-high" ~ "ResHigh", 
    landuse == "R-low" ~ "ResLow", 
    landuse == "R-other" ~ "ResOther", 
  ))

## GIS data ----
# Quadrat point layer. 
quadrat <- 
  st_read(dsn = "RawData/SampleQuadrat", layer = "Sample_plot") %>% 
  select(Qua_id, geometry) %>% 
  st_transform(6668) %>% 
  rename(qua_id = Qua_id)

# Land use *.shp data. 
land.use <- 
  st_read("RawData/LandUse/京都市用途地域_JGD2000.shp") %>% 
  rename("land_use" = "Land_class") %>% 
  mutate(land_use = case_when(
    land_use == "Com" ~ "Com", 
    land_use == "Com neigh" ~ "ComNbr", 
    land_use == "Ind" ~ "Ind", 
    land_use == "R high" ~ "ResHigh", 
    land_use == "R low" ~ "ResLow", 
    land_use == "R resi" ~ "ResOther", 
  )) %>% 
  st_transform(6668)

# ecosystem services values interpolation by EBK
esv.ebk <- vector("list", 7)
names(esv.ebk) <- kES$abbr
for (i in kES$abbr) {
  esv.ebk[[i]] <- rast(paste0("RawData/ESVEBK/", i, ".tif")) %>% 
    project("EPSG:6668")
}

## Species information ----
species.info <- read.csv("RawData/Plant_info.csv") %>% 
  tibble() %>% 
  rename_with(tolower) %>% 
  rename(species = species_lt)

## Individual tree attr and ES ----
# Including ES, investigation data, and quadrat information. 
indv.data <- 
  # ES part: raw data from Access database from Hirabayashi 
  read.xlsx("RawData/Output_i_tree.xlsx", sheet = "Trees") %>% 
  tibble() %>% 
  rename(tree_id = "TreeID", 
         dbh = "DBH.(CM)", 
         height = "HEIGHT.(M)", 
         lai = "LEAF.AREA.INDEX", 
         carbon_stor = "CARBON.STORAGE.(KG)", 
         carbon_seq = "GROSS.CARBON.SEQ.(KG/YR)", 
         no2_rem = "NO2.Removal.(g)", 
         o3_rem = "O3.Removal.(g)", 
         pm25_rem = "PM25.Removal.(g)", 
         so2_rem = "SO2.Removal.(g)", 
         no2_rem_val = "NO2.Value.($)", 
         o3_rem_val = "O3.Value.($)", 
         pm25_rem_val = "PM25.Value.($)",          
         so2_rem_val = "SO2.Value.($)", 
         ro_rd = "Avoided.Runoff.(m3)") %>% 
  # Add units. 
  mutate(
    dbh = set_units(dbh, cm), 
    height = set_units(height, m), 
    lai = set_units(lai, 1), 
    carbon_stor = set_units(carbon_stor, kg), 
    carbon_seq = set_units(carbon_seq, kg), 
    no2_rem = set_units(no2_rem, g), 
    o3_rem = set_units(o3_rem, g), 
    pm25_rem = set_units(pm25_rem, g), 
    so2_rem = set_units(so2_rem, g), 
    no2_rem_val = set_units(no2_rem_val, dollar), 
    o3_rem_val = set_units(o3_rem_val, dollar), 
    pm25_rem_val = set_units(pm25_rem_val, dollar),          
    so2_rem_val = set_units(so2_rem_val, dollar), 
    ro_rd = set_units(ro_rd, m3)
  ) %>% 
  # Order by res_tree_id so that it can be bind with investigation data. 
  arrange(tree_id) %>% 
  mutate(
    # Turn monetary value from Japanese Yen to US dollar. 
    # Calculate carbon monetary value and turn to US dollar: the carbon price in Japan is 10600 JPY/ton carbon = 10.6 JPY/kg carbon. 
    carbon_stor_val = 10.6 * carbon_stor / kUsdJpy,
    carbon_seq_val = 10.6 * carbon_seq / kUsdJpy, 
    # Calculate runoff reduction value and turn to US dollars: runoff reduction value in Japan is 719 JPY/cubic meter rainwater. 
    ro_rd_val = 719 * ro_rd / kUsdJpy
  ) %>% 
  # Investigation data part: has the same order with the previous data. 
  cbind(
    read.csv("RawData/Plant_data.csv") %>% 
      tibble() %>% 
      rename_with(tolower) %>% 
      rename(species = species_lt) %>% 
      subset(tree_shrub == "tree") %>% 
      arrange(plot_id, plant_id)
  ) %>% 
  tibble() %>% 
  # Match qua_id (Quadrat id of previous Kyoto plant diversity project) and kes_qua_id (quadrat ID of previous Kyoto urban ecosystem services project). 
  left_join(
    read.csv("RawData/Input_i_tree.csv") %>% 
      rename(tree_id = ID, 
             kes_qua_id = PlotId) %>% 
      select(kes_qua_id, tree_id), 
    by = "tree_id"
  ) %>% 
  # Add quadrat information part. 
  left_join(qua.info, by = "kes_qua_id") %>% 
  # Add species information. 
  left_join(species.info, by = "species") %>% 
  # Get target variables. 
  select(
    # Basic information. 
    qua_id, tree_id, ward, landuse, species, genus, family, 
    # Tree attribute. 
    dbh, height, lai, 
    # ES and ES value. 
    all_of(kES$es), all_of(kES$esv)
  )

## Quadrat tree attr and ES ----
qua.data <- indv.data %>% 
  group_by(qua_id, landuse) %>% 
  summarise(
    richness = length(unique(species)), 
    abundance = n(), 
    # Mean and median values of tree attributes. 
    dbh_mean = mean(dbh), 
    dbg_mid = median(dbh), 
    height_mean = mean(height), 
    height_mid = median(height), 
    lai_mean = mean(lai), 
    lai_mid = median(lai), 
    # Sum of ES and revise unit. 
    across(all_of(kES$es), sum), 
    across(all_of(kES$es), drop_units)
  ) %>% 
  ungroup() %>% 
  mutate(
    carbon_stor = set_units(carbon_stor, kg/quadrat), 
    carbon_seq = set_units(carbon_seq, kg/quadrat), 
    no2_rem = set_units(no2_rem, g/quadrat), 
    o3_rem = set_units(o3_rem, g/quadrat), 
    pm25_rem = set_units(pm25_rem, g/quadrat), 
    so2_rem = set_units(so2_rem, g/quadrat), 
    ro_rd = set_units(ro_rd, m3/quadrat)
  ) %>% 
  # Join quadrat ecosystem service results to quadrat layer. 
  left_join(quadrat, by = "qua_id") %>% 
  st_as_sf() %>% 
  # Remove Z value in coord. 
  st_zm()

## Land use tree attr and ES ----
lu.data <- left_join(
  # Tree attribute of each land use, generally mean or median of all trees. 
  indv.data %>% 
    group_by(landuse) %>% 
    summarise(
      qua_num = n_distinct(qua_id), 
      # Calculate all species of the quadrats as the richness of the land use.
      richness = length(unique(species)), 
      density = n() / qua_num, 
      dbh_mean = mean(dbh), 
      dbh_mid = median(dbh), 
      height_mean = mean(height), 
      height_mid = median(height), 
      lai_mean = mean(lai), 
      lai_mid = median(lai)
    ), 
  # Total ESV of each land use generated by EBK. 
  lapply(esv.ebk, SumESVLanduse) %>% 
    do.call(rbind, .) %>% 
    t() %>% 
    data.frame() %>% 
    rename(
      carbon_stor_val = CS, 
      carbon_seq_val = CSE, 
      no2_rem_val = NO2, 
      o3_rem_val = O3, 
      pm25_rem_val = PM2.5, 
      so2_rem_val = SO2, 
      ro_rd_val = RR
    ) %>% 
    mutate(landuse = rownames(.), .before = ), 
  by = "landuse"
) %>% 
  # Add units to ESV. 
  mutate(
    carbon_stor_val = set_units(carbon_stor_val, dollar), 
    carbon_seq_val = set_units(carbon_seq_val, dollar), 
    no2_rem_val = set_units(no2_rem_val, dollar), 
    o3_rem_val = set_units(o3_rem_val, dollar), 
    pm25_rem_val = set_units(pm25_rem_val, dollar),          
    so2_rem_val = set_units(so2_rem_val, dollar), 
    ro_rd_val = set_units(ro_rd_val, dollar)
  ) %>% 
  # Reorder land use. 
  mutate(landuse = factor(landuse, levels = kLanduse))

# Analysis ----
## Tree attribute ----
# Number of species and families. 
cat("\n", "total species:", length(unique(indv.data$species)), "\n", 
    "total genera:", length(unique(indv.data$genus)), "\n", 
    "total families:", length(unique(indv.data$family)), "\n", "\n")

# Top abundant species of each land use. 
lu.top.species <- indv.data %>% 
  group_by(landuse, species) %>% 
  summarise(abundance = n()) %>% 
  group_by(landuse) %>% 
  mutate(rel_abundance = abundance / sum(abundance)) %>% 
  slice_max(order_by = rel_abundance, n = 10) %>% 
  # Since some species have equal relative abundance, the "top 10" species list might be of a size larger than 10, so I further slice the data by head 10 species. 
  slice_head(n = 10) %>% 
  ungroup() %>% 
  mutate(landuse = factor(landuse, levels = kLanduse)) %>% 
  arrange(landuse, rel_abundance) %>% 
  mutate(rowid = row_number())
png("ProcData/Top_species_of_each_land_use.png", 
    width = 3000, height = 1200, res = 300)
(lu.top.species %>% 
    ggplot() + 
    geom_col(aes(x = rowid, y = rel_abundance)) + 
    scale_x_continuous(
      breaks = lu.top.species$rowid, labels = lu.top.species$species
    ) + 
    lims(y = c(0, 0.6)) + 
    labs(x = "Species", y = "Relative Abundance") + 
    coord_flip() + 
    theme(axis.text.y = element_text(face = "italic")) + 
    facet_wrap(.~ landuse, scales = "free"))
dev.off()

# Tree attribute of each land use. 
lu.data %>% 
  drop_units() %>% 
  select(landuse, richness, density, dbh_mean, dbh_mid, 
         height_mean, height_mid, lai_mean, lai_mid) %>% 
  pivot_longer(cols = -landuse, names_to = "attr", values_to = "val") %>% 
  ggplot() + 
  geom_bar(aes(landuse, val), stat = "identity") + 
  theme(axis.text.x = element_text(angle = 90)) +
  facet_wrap(.~ attr, scales = "free")

## Interpolation ----
### Interpolation preparation ----
# visualization of land use pattern and distribution of quadrats
tm_shape(land.use) + 
  tm_polygons(col = "land_use") +
  tmap_options(check.and.fix = TRUE) + 
  tm_shape(qua.data) + 
  tm_dots()
# export the *.shp file and send it ArcGIS
st_write(qua.data, "ProcData/Qua_es_shp/Qua_es.shp", append = FALSE)
# It should be noted that, when exporting the sf to *.shp, the column names will be abbreviated. 

### GIS interpolation ----
# Based on the data ProcData/Qua_es.shp generated in the last step, multiple interpolation methods were applied using ArcGIS. During the interpolation, a cross-validation result was generated for each ES for each interpolation method, and they are stored in RawData/Validation folder of this project. 

### Cross-validation ----
# Based on RawData/Validation data, errors were calculated to choose "the best interpolation method" for mapping each ES. 
val.base <- 
  # Get all *.dbf and bind them into data.frame. 
  do.call(
    rbind, 
    list(
      lapply(kES$abbr, ReadDbf, intrpl = "EBK") %>% 
        do.call(rbind, .), 
      lapply(kES$abbr, ReadDbf, intrpl = "IDW") %>% 
        do.call(rbind, .), 
      lapply(kES$abbr, ReadDbf, intrpl = "OK") %>% 
        do.call(rbind, .), 
      lapply(kES$abbr, ReadDbf, intrpl = "RBF") %>% 
        do.call(rbind, .)
    )
  ) %>% 
  # Get difference between measured and predicted values. 
  mutate(
    abs_diff = abs(predicted - measured), abs_diff_sqr = abs_diff ^ 2
  )
val.res <- 
  val.base %>% 
  # Calculate validation errors. 
  group_by(intrpl, es) %>% 
  summarise(
    mae = sum(abs_diff) / n(), rmse = sqrt(sum(abs_diff_sqr) / n())
  ) %>% 
  ungroup()
# Print the results by validation error type. 
lapply(
  c("mae", "rmse"), 
  function(x) {
    val.res %>% 
      select(all_of(c("intrpl", "es", x))) %>% 
      pivot_wider(id_cols = intrpl, 
                  names_from = es, 
                  values_from = all_of(x)) %>% 
      mutate(error = x, .before = "intrpl")
  }
) %>% 
  write.xlsx(file = "ProcData/Cross_validation_result.xlsx")
# Get the min value for each error. 
pivot_longer(
  val.res, cols = c(mae, rmse), names_to = "cross_idx", values_to = "cross_val"
) %>%  
  group_by(cross_idx, es) %>% 
  mutate(min = (cross_val == min(cross_val))) %>% 
  ungroup() %>% 
  filter(min) %>% 
  select(cross_idx, es, intrpl) %>% 
  mutate(es = factor(es, levels = kES$abbr)) %>% 
  arrange(cross_idx, es)
# Visualize the MAE and RMSE. 
pivot_longer(
  val.res, cols = c(mae, rmse), names_to = "cross_idx", values_to = "cross_val"
) %>% 
  ggplot() + 
  geom_col(aes(intrpl, cross_val)) + 
  facet_wrap(cross_idx ~ es, nrow = 2, scales = "free")

### Best interpolation ----
# According to MAE and RMSE results, the "best interpolation" method is EBK, so we exported the ES interpolation results (see RawData/ESEBK folder) and ESV interpolation results (see RawData/ESVEBK folder). 

## Analysis of results ----
# Calculate total ESV of each land use by adding up the values of all the grids of the ArcGIS data. 
lu.data %>% 
  select(landuse, all_of(kES$esv)) %>% 
  pivot_longer(cols = all_of(kES$esv), names_to = "es", values_to = "val") %>% 
  group_by(landuse) %>% 
  summarise(val = sum(val)) %>% 
  ungroup()
# plot for total ESV of each land use
png("ProcData/Total_es_value_of_each_land_use.png", 
    width = 1500, height = 1200, res = 300)
(
  lu.data %>% 
    select(landuse, all_of(kES$esv)) %>% 
    pivot_longer(cols = all_of(kES$esv), names_to = "esv", values_to = "val") %>% 
    left_join(kES, by = "esv") %>% 
    mutate(abbr = factor(abbr, levels = kES$abbr), 
           val = drop_units(val), 
           landuse = factor(landuse, levels = kLanduse)) %>% 
    ggplot() + 
    geom_bar(aes(landuse, val / 10^6, fill = abbr), 
             stat = "identity", position = "stack") + 
    labs(x = "", y = "Total ESV (million dollar)") + 
    scale_fill_manual(
      name = NULL, 
      limits = c("CS", "CSE", "NO2", "O3", "PM2.5", "SO2", "RR"), 
      labels = c("CS", "CSE", 
                 bquote(NO[2]), bquote(O[3]), bquote(PM[2.5]), bquote(SO[2]), 
                 "RR"), 
      values = c("#AF2D2D", "#F4913F", 
                 "#F4F33F", "#A5AC2D", "#B4EC3D", "#017901", 
                 "#4378CC")
    ) + 
    theme_bw()
)
dev.off()

# The analysis of relationship between ES, land use, and urban planing layers was conducted in GIS. For details, see the manuscript. 
